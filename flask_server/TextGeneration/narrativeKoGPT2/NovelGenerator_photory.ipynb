{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0p6JShGUnpZ"
   },
   "source": [
    "# 학습된 NarrativeKoGPT2을 이용한 Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JV7_Ye-1UuS2"
   },
   "source": [
    "## 1.Google Drive 연동\n",
    "- 모델 파일과 학습 데이터가 저장 되어있는 구글 드라이브의 디렉토리와 Colab을 연동. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vi2gIIroVXeS"
   },
   "source": [
    "### 1.1 Google Drive 연동\n",
    "아래 코드를 실행후 나오는 URL을 클릭하여 나오는 인증 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpCSwfFGkRx7"
   },
   "source": [
    "**Colab 디렉토리 아래 NarrativeKoGPT2 경로 확인**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVmhNd21kse2"
   },
   "source": [
    "**필요 패키지들 설치**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBTFp-P8ihuM"
   },
   "source": [
    "**시스템 경로 추가**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hnSOCChk9lU"
   },
   "source": [
    "## 2.KoGPT2 Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OL6xVLtHn6vK"
   },
   "source": [
    "### 2.1.Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17437,
     "status": "ok",
     "timestamp": 1584960386687,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17497395371430681608"
     },
     "user_tz": -540
    },
    "id": "-IGI-Rcakhsw",
    "outputId": "3453daa2-e098-4f8f-952c-b8a340157364"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "from gluonnlp.data import SentencepieceTokenizer \n",
    "from kogpt2.utils import get_tokenizer\n",
    "from kogpt2.utils import download, tokenizer\n",
    "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\n",
    "from model.torch_gpt2 import GPT2Config, GPT2LMHeadModel\n",
    "from util.data import NovelDataset\n",
    "import gluonnlp\n",
    "import sampling\n",
    "import kss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G20dHg4mn5x4"
   },
   "source": [
    "### 2.2. koGPT-2 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPoFzMKkk8eB"
   },
   "outputs": [],
   "source": [
    "ctx= 'cpu'#'cuda' #'cpu' #학습 Device CPU or GPU. colab의 경우 GPU 사용\n",
    "cachedir='~/kogpt2/' # KoGPT-2 모델 다운로드 경로\n",
    "#epoch = 500  # 학습 epoch\n",
    "save_path = 'checkpoints/'\n",
    "load_path = 'checkpoints/narrativeKoGPT2_checkpoint_tokenized_ver3_bat1_epoch100.tar'\n",
    "use_cuda = True # Colab내 GPU 사용을 위한 값\n",
    "\n",
    "pytorch_kogpt2 = {\n",
    "    'url': 'https://kobert.blob.core.windows.net/models/kogpt2/pytorch/pytorch_kogpt2_676e9bcfa7.params',\n",
    "    'fname': 'pytorch_kogpt2_676e9bcfa7.params',\n",
    "    'chksum': '676e9bcfa7'\n",
    "}\n",
    "kogpt2_config = {\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"layer_norm_epsilon\": 1e-05,\n",
    "    \"n_ctx\": 1024,\n",
    "    \"n_embd\": 768,\n",
    "    \"n_head\": 12,\n",
    "    \"n_layer\": 12,\n",
    "    \"n_positions\": 1024,\n",
    "    \"vocab_size\": 50000,\n",
    "    \"activation_function\": \"gelu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xIXykCtn45d"
   },
   "source": [
    "### 2.3 Model and Vocab Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27090,
     "status": "ok",
     "timestamp": 1584960442452,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17497395371430681608"
     },
     "user_tz": -540
    },
    "id": "kvtLJGh5o0MZ",
    "outputId": "ed97678f-f8d5-40b7-a7ef-6e6e6760eb7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# download model\n",
    "model_info = pytorch_kogpt2\n",
    "model_path = download(model_info['url'],\n",
    "                       model_info['fname'],\n",
    "                       model_info['chksum'],\n",
    "                       cachedir=cachedir)\n",
    "# download vocab\n",
    "vocab_info = tokenizer\n",
    "vocab_path = download(vocab_info['url'],\n",
    "                       vocab_info['fname'],\n",
    "                       vocab_info['chksum'],\n",
    "                       cachedir=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fu7-2csBpLQR"
   },
   "source": [
    "### 2.4.KoGPT-2 Model Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQ0PI30pnJyR"
   },
   "source": [
    "**추론 및 학습 재개를 위한 모델 불러오기**\n",
    "**저장하기**\n",
    "```python\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "```\n",
    "  \n",
    "**불러오기**\n",
    "``` python\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5AK_S6spqwQ"
   },
   "outputs": [],
   "source": [
    "# Device 설정\n",
    "device = torch.device(ctx)\n",
    "# 저장한 Checkpoint 불러오기\n",
    "checkpoint = torch.load(load_path, map_location=device)\n",
    "\n",
    "# KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n",
    "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\\\n",
    "## 자기 학습한 모델\n",
    "kogpt2model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# skt-ai의 모델\n",
    "#kogpt2model.load_state_dict(torch.load(model_path))\n",
    "kogpt2model.to(device)\n",
    "    \n",
    "kogpt2model.eval()\n",
    "vocab_b_obj = gluonnlp.vocab.BERTVocab.from_sentencepiece(vocab_path,\n",
    "                                                     mask_token=None,\n",
    "                                                     sep_token=None,\n",
    "                                                     cls_token=None,\n",
    "                                                     unknown_token='<unk>',\n",
    "                                                     padding_token='<pad>',\n",
    "                                                     bos_token='<s>',\n",
    "                                                     eos_token='</s>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rnV010Wq9Xw"
   },
   "source": [
    "### 2.5. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432,
     "status": "ok",
     "timestamp": 1584961212085,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17497395371430681608"
     },
     "user_tz": -540
    },
    "id": "Ukfj9FPHpwfk",
    "outputId": "d28e204b-9096-4beb-a0d0-e28b55588c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tok_path = get_tokenizer()\n",
    "model, vocab = kogpt2model, vocab_b_obj\n",
    "tok = SentencepieceTokenizer(tok_path, num_best = 0, alpha=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sgd28DRhthzo"
   },
   "source": [
    "### 2.6. NarrativeKoGPT-2 Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYkDU-cbrduY"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "문장 입력:  서핑 보드를 타는 한 남자\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁서', '핑', '▁보', '드를', '▁타는', '▁한', '▁남자']\n",
      "selected token: 만이 softmax value:tensor(0.0398, grad_fn=<SelectBackward>)\n",
      "selected token: ▁조용히 softmax value:tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "selected token: ▁요 softmax value:tensor(0.0061, grad_fn=<SelectBackward>)\n",
      "selected token: 람 softmax value:tensor(0.7639, grad_fn=<SelectBackward>)\n",
      "selected token: 에 softmax value:tensor(0.0300, grad_fn=<SelectBackward>)\n",
      "selected token: ▁폴 softmax value:tensor(0.0586, grad_fn=<SelectBackward>)\n",
      "selected token: 짝 softmax value:tensor(0.9999, grad_fn=<SelectBackward>)\n",
      "selected token: 폴 softmax value:tensor(0.9543, grad_fn=<SelectBackward>)\n",
      "selected token: 짝 softmax value:tensor(0.9999, grad_fn=<SelectBackward>)\n",
      "selected token: ▁모여 softmax value:tensor(0.0102, grad_fn=<SelectBackward>)\n",
      "selected token: 들어 softmax value:tensor(0.0301, grad_fn=<SelectBackward>)\n",
      "selected token: ▁자신의 softmax value:tensor(0.0089, grad_fn=<SelectBackward>)\n",
      "selected token: ▁몸 softmax value:tensor(0.0038, grad_fn=<SelectBackward>)\n",
      "selected token: ▁안에 softmax value:tensor(0.0639, grad_fn=<SelectBackward>)\n",
      "selected token: ▁장 softmax value:tensor(0.0030, grad_fn=<SelectBackward>)\n",
      "selected token: 기가 softmax value:tensor(0.0214, grad_fn=<SelectBackward>)\n",
      "selected token: ▁가득 softmax value:tensor(0.1031, grad_fn=<SelectBackward>)\n",
      "selected token: ▁차 softmax value:tensor(0.4353, grad_fn=<SelectBackward>)\n",
      "selected token: 도록 softmax value:tensor(0.3011, grad_fn=<SelectBackward>)\n",
      "selected token: ▁폴 softmax value:tensor(0.0209, grad_fn=<SelectBackward>)\n",
      "selected token: 짝 softmax value:tensor(1.0000, grad_fn=<SelectBackward>)\n",
      "selected token: ▁뛰고 softmax value:tensor(0.1377, grad_fn=<SelectBackward>)\n",
      "selected token: ▁있었다 softmax value:tensor(0.2442, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9935, grad_fn=<SelectBackward>)\n",
      "selected token: ▁바닥에 softmax value:tensor(0.0015, grad_fn=<SelectBackward>)\n",
      "selected token: ▁자기 softmax value:tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "selected token: ▁주 softmax value:tensor(0.0047, grad_fn=<SelectBackward>)\n",
      "selected token: 전자 softmax value:tensor(0.2784, grad_fn=<SelectBackward>)\n",
      "selected token: ▁네 softmax value:tensor(0.0085, grad_fn=<SelectBackward>)\n",
      "selected token: ▁개 softmax value:tensor(0.5709, grad_fn=<SelectBackward>)\n",
      "selected token: 까지 softmax value:tensor(0.0106, grad_fn=<SelectBackward>)\n",
      "selected token: ▁내놓은 softmax value:tensor(0.0089, grad_fn=<SelectBackward>)\n",
      "selected token: ▁건 softmax value:tensor(0.0067, grad_fn=<SelectBackward>)\n",
      "selected token: 장한 softmax value:tensor(0.9052, grad_fn=<SelectBackward>)\n",
      "selected token: ▁청년이 softmax value:tensor(0.0498, grad_fn=<SelectBackward>)\n",
      "selected token: ▁다른 softmax value:tensor(0.0044, grad_fn=<SelectBackward>)\n",
      "selected token: ▁사람 softmax value:tensor(0.0203, grad_fn=<SelectBackward>)\n",
      "selected token: ▁앞에 softmax value:tensor(0.1560, grad_fn=<SelectBackward>)\n",
      "selected token: ▁주 softmax value:tensor(0.0184, grad_fn=<SelectBackward>)\n",
      "selected token: 름을 softmax value:tensor(0.0236, grad_fn=<SelectBackward>)\n",
      "selected token: ▁잡을 softmax value:tensor(0.0211, grad_fn=<SelectBackward>)\n",
      "selected token: ▁사이에 softmax value:tensor(0.0266, grad_fn=<SelectBackward>)\n",
      "selected token: ▁어디 softmax value:tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "selected token: ▁한 softmax value:tensor(0.5179, grad_fn=<SelectBackward>)\n",
      "selected token: ▁눈 softmax value:tensor(0.0823, grad_fn=<SelectBackward>)\n",
      "selected token: ▁팔 softmax value:tensor(0.9163, grad_fn=<SelectBackward>)\n",
      "selected token: ▁여유가 softmax value:tensor(0.5328, grad_fn=<SelectBackward>)\n",
      "selected token: ▁없어 softmax value:tensor(0.1056, grad_fn=<SelectBackward>)\n",
      "selected token: ▁보였다 softmax value:tensor(0.9484, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9996, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그냥 softmax value:tensor(0.0012, grad_fn=<SelectBackward>)\n",
      "selected token: ▁일어나 softmax value:tensor(0.0015, grad_fn=<SelectBackward>)\n",
      "selected token: ▁맥주 softmax value:tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "selected token: ▁잔 softmax value:tensor(0.0459, grad_fn=<SelectBackward>)\n",
      "selected token: 을 softmax value:tensor(0.4883, grad_fn=<SelectBackward>)\n",
      "selected token: ▁앞에 softmax value:tensor(0.0121, grad_fn=<SelectBackward>)\n",
      "selected token: ▁놓고 softmax value:tensor(0.9686, grad_fn=<SelectBackward>)\n",
      "selected token: ▁지하 softmax value:tensor(0.0011, grad_fn=<SelectBackward>)\n",
      "selected token: 실로 softmax value:tensor(0.6518, grad_fn=<SelectBackward>)\n",
      "selected token: ▁들어갔다 softmax value:tensor(0.2259, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9972, grad_fn=<SelectBackward>)\n",
      "selected token: ▁한낮 softmax value:tensor(0.0008, grad_fn=<SelectBackward>)\n",
      "selected token: 의 softmax value:tensor(0.4449, grad_fn=<SelectBackward>)\n",
      "selected token: ▁열기를 softmax value:tensor(0.7449, grad_fn=<SelectBackward>)\n",
      "selected token: ▁식 softmax value:tensor(0.9150, grad_fn=<SelectBackward>)\n",
      "selected token: 히려 softmax value:tensor(0.7807, grad_fn=<SelectBackward>)\n",
      "selected token: 는 softmax value:tensor(0.3544, grad_fn=<SelectBackward>)\n",
      "selected token: ▁본능 softmax value:tensor(0.0035, grad_fn=<SelectBackward>)\n",
      "selected token: 이 softmax value:tensor(0.5814, grad_fn=<SelectBackward>)\n",
      "selected token: ▁서 softmax value:tensor(0.0025, grad_fn=<SelectBackward>)\n",
      "selected token: 도 softmax value:tensor(0.0091, grad_fn=<SelectBackward>)\n",
      "selected token: ▁건 softmax value:tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "selected token: 실 softmax value:tensor(0.0417, grad_fn=<SelectBackward>)\n",
      "selected token: 하게 softmax value:tensor(0.3050, grad_fn=<SelectBackward>)\n",
      "selected token: ▁몸에 softmax value:tensor(0.0240, grad_fn=<SelectBackward>)\n",
      "selected token: ▁익 softmax value:tensor(0.1398, grad_fn=<SelectBackward>)\n",
      "selected token: 은 softmax value:tensor(0.3974, grad_fn=<SelectBackward>)\n",
      "selected token: ▁상태였다 softmax value:tensor(0.0052, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9998, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그걸 softmax value:tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "selected token: ▁본 softmax value:tensor(0.5513, grad_fn=<SelectBackward>)\n",
      "selected token: ▁소년 softmax value:tensor(0.0045, grad_fn=<SelectBackward>)\n",
      "selected token: 은 softmax value:tensor(0.9522, grad_fn=<SelectBackward>)\n",
      "selected token: ▁이 softmax value:tensor(0.0067, grad_fn=<SelectBackward>)\n",
      "selected token: ▁거대한 softmax value:tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "selected token: ▁무 softmax value:tensor(0.0067, grad_fn=<SelectBackward>)\n",
      "selected token: 쇠 softmax value:tensor(0.9920, grad_fn=<SelectBackward>)\n",
      "selected token: ▁난 softmax value:tensor(0.9399, grad_fn=<SelectBackward>)\n",
      "selected token: 로에서 softmax value:tensor(0.2444, grad_fn=<SelectBackward>)\n",
      "selected token: ▁생 softmax value:tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "selected token: 쥐 softmax value:tensor(0.6160, grad_fn=<SelectBackward>)\n",
      "selected token: 를 softmax value:tensor(0.3143, grad_fn=<SelectBackward>)\n",
      "selected token: ▁발견 softmax value:tensor(0.0052, grad_fn=<SelectBackward>)\n",
      "selected token: 하곤 softmax value:tensor(0.9729, grad_fn=<SelectBackward>)\n",
      "selected token: ▁생 softmax value:tensor(0.0054, grad_fn=<SelectBackward>)\n",
      "selected token: 쥐 softmax value:tensor(1.0000, grad_fn=<SelectBackward>)\n",
      "selected token: 를 softmax value:tensor(0.5211, grad_fn=<SelectBackward>)\n",
      "selected token: ▁놓 softmax value:tensor(0.0016, grad_fn=<SelectBackward>)\n",
      "selected token: 아주 softmax value:tensor(0.2172, grad_fn=<SelectBackward>)\n",
      "selected token: 었다 softmax value:tensor(0.9175, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9942, grad_fn=<SelectBackward>)\n",
      "selected token: ▁병 softmax value:tensor(0.0022, grad_fn=<SelectBackward>)\n",
      "selected token: 사가 softmax value:tensor(0.2166, grad_fn=<SelectBackward>)\n",
      "selected token: ▁어 softmax value:tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "selected token: 슬 softmax value:tensor(0.0150, grad_fn=<SelectBackward>)\n",
      "selected token: 렁 softmax value:tensor(1.0000, grad_fn=<SelectBackward>)\n",
      "selected token: ▁거 softmax value:tensor(0.6494, grad_fn=<SelectBackward>)\n",
      "selected token: 리며 softmax value:tensor(0.8961, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그를 softmax value:tensor(0.0427, grad_fn=<SelectBackward>)\n",
      "selected token: ▁향해 softmax value:tensor(0.0035, grad_fn=<SelectBackward>)\n",
      "selected token: ▁총을 softmax value:tensor(0.0147, grad_fn=<SelectBackward>)\n",
      "selected token: ▁ softmax value:tensor(0.3176, grad_fn=<SelectBackward>)\n",
      "selected token: ▁발사 softmax value:tensor(0.0918, grad_fn=<SelectBackward>)\n",
      "selected token: 했지만 softmax value:tensor(0.2412, grad_fn=<SelectBackward>)\n",
      "selected token: ▁정확히 softmax value:tensor(0.0019, grad_fn=<SelectBackward>)\n",
      "selected token: ▁몸 softmax value:tensor(0.0069, grad_fn=<SelectBackward>)\n",
      "selected token: ▁속의 softmax value:tensor(0.0855, grad_fn=<SelectBackward>)\n",
      "selected token: ▁생 softmax value:tensor(0.8180, grad_fn=<SelectBackward>)\n",
      "selected token: 쥐 softmax value:tensor(0.9999, grad_fn=<SelectBackward>)\n",
      "selected token: 를 softmax value:tensor(0.8286, grad_fn=<SelectBackward>)\n",
      "selected token: ▁맞추 softmax value:tensor(0.8040, grad_fn=<SelectBackward>)\n",
      "selected token: 지는 softmax value:tensor(0.7459, grad_fn=<SelectBackward>)\n",
      "selected token: ▁못했다 softmax value:tensor(0.7698, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9998, grad_fn=<SelectBackward>)\n",
      "selected token: ▁깜짝 softmax value:tensor(0.0023, grad_fn=<SelectBackward>)\n",
      "selected token: ▁놀란 softmax value:tensor(0.9396, grad_fn=<SelectBackward>)\n",
      "selected token: ▁병 softmax value:tensor(0.2556, grad_fn=<SelectBackward>)\n",
      "selected token: 사가 softmax value:tensor(0.9757, grad_fn=<SelectBackward>)\n",
      "selected token: ▁살 softmax value:tensor(0.0009, grad_fn=<SelectBackward>)\n",
      "selected token: 살 softmax value:tensor(0.3841, grad_fn=<SelectBackward>)\n",
      "selected token: ▁나무 softmax value:tensor(0.0030, grad_fn=<SelectBackward>)\n",
      "selected token: 라며 softmax value:tensor(0.3997, grad_fn=<SelectBackward>)\n",
      "selected token: ▁난 softmax value:tensor(0.0022, grad_fn=<SelectBackward>)\n",
      "selected token: 로 softmax value:tensor(0.9616, grad_fn=<SelectBackward>)\n",
      "selected token: ▁쪽으로 softmax value:tensor(0.1470, grad_fn=<SelectBackward>)\n",
      "selected token: ▁기어 softmax value:tensor(0.5099, grad_fn=<SelectBackward>)\n",
      "selected token: 갔 softmax value:tensor(0.0327, grad_fn=<SelectBackward>)\n",
      "selected token: 어요 softmax value:tensor(0.6900, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9985, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그는 softmax value:tensor(0.0294, grad_fn=<SelectBackward>)\n",
      "selected token: ▁여 softmax value:tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "selected token: 우가 softmax value:tensor(0.0492, grad_fn=<SelectBackward>)\n",
      "selected token: ▁떠올 softmax value:tensor(0.0008, grad_fn=<SelectBackward>)\n",
      "selected token: 랐던 softmax value:tensor(0.2742, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그 softmax value:tensor(0.1477, grad_fn=<SelectBackward>)\n",
      "selected token: ▁젊은 softmax value:tensor(0.0126, grad_fn=<SelectBackward>)\n",
      "selected token: 이의 softmax value:tensor(0.8517, grad_fn=<SelectBackward>)\n",
      "selected token: ▁얼굴에 softmax value:tensor(0.0023, grad_fn=<SelectBackward>)\n",
      "selected token: ▁경 softmax value:tensor(0.0024, grad_fn=<SelectBackward>)\n",
      "selected token: 련 softmax value:tensor(0.3219, grad_fn=<SelectBackward>)\n",
      "selected token: 이 softmax value:tensor(0.6662, grad_fn=<SelectBackward>)\n",
      "selected token: ▁일 softmax value:tensor(0.8489, grad_fn=<SelectBackward>)\n",
      "selected token: 며 softmax value:tensor(0.6378, grad_fn=<SelectBackward>)\n",
      "selected token: ▁화를 softmax value:tensor(0.0008, grad_fn=<SelectBackward>)\n",
      "selected token: ▁내며 softmax value:tensor(0.8273, grad_fn=<SelectBackward>)\n",
      "selected token: ▁고개를 softmax value:tensor(0.0017, grad_fn=<SelectBackward>)\n",
      "selected token: ▁쳐 softmax value:tensor(0.0078, grad_fn=<SelectBackward>)\n",
      "selected token: 들고 softmax value:tensor(0.6371, grad_fn=<SelectBackward>)\n",
      "selected token: ▁서 softmax value:tensor(0.0609, grad_fn=<SelectBackward>)\n",
      "selected token: ▁있 softmax value:tensor(0.0579, grad_fn=<SelectBackward>)\n",
      "selected token: 질 softmax value:tensor(0.5026, grad_fn=<SelectBackward>)\n",
      "selected token: ▁못했다 softmax value:tensor(0.3537, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9977, grad_fn=<SelectBackward>)\n",
      "selected token: ▁마치 softmax value:tensor(0.0010, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그의 softmax value:tensor(0.0077, grad_fn=<SelectBackward>)\n",
      "selected token: ▁악마 softmax value:tensor(0.0027, grad_fn=<SelectBackward>)\n",
      "selected token: 적인 softmax value:tensor(0.5088, grad_fn=<SelectBackward>)\n",
      "selected token: ▁마음 softmax value:tensor(0.0219, grad_fn=<SelectBackward>)\n",
      "selected token: 씨가 softmax value:tensor(0.7471, grad_fn=<SelectBackward>)\n",
      "selected token: ▁잔 softmax value:tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "selected token: 인한 softmax value:tensor(0.9455, grad_fn=<SelectBackward>)\n",
      "selected token: ▁형을 softmax value:tensor(0.0077, grad_fn=<SelectBackward>)\n",
      "selected token: ▁또 softmax value:tensor(0.0016, grad_fn=<SelectBackward>)\n",
      "selected token: ▁한 softmax value:tensor(0.0364, grad_fn=<SelectBackward>)\n",
      "selected token: ▁번 softmax value:tensor(0.9993, grad_fn=<SelectBackward>)\n",
      "selected token: ▁맞은 softmax value:tensor(0.0897, grad_fn=<SelectBackward>)\n",
      "selected token: ▁듯 softmax value:tensor(0.1627, grad_fn=<SelectBackward>)\n",
      "selected token: ▁했기 softmax value:tensor(0.0091, grad_fn=<SelectBackward>)\n",
      "selected token: ▁때문이다 softmax value:tensor(0.5174, grad_fn=<SelectBackward>)\n",
      "selected token: . softmax value:tensor(0.9998, grad_fn=<SelectBackward>)\n",
      "selected token: ▁순간 softmax value:tensor(0.0060, grad_fn=<SelectBackward>)\n",
      "selected token: 적인 softmax value:tensor(0.0012, grad_fn=<SelectBackward>)\n",
      "selected token: ▁화 softmax value:tensor(0.0081, grad_fn=<SelectBackward>)\n",
      "selected token: 와 softmax value:tensor(0.0159, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그로 softmax value:tensor(0.0099, grad_fn=<SelectBackward>)\n",
      "selected token: ▁인한 softmax value:tensor(0.7290, grad_fn=<SelectBackward>)\n",
      "selected token: ▁자신의 softmax value:tensor(0.0067, grad_fn=<SelectBackward>)\n",
      "selected token: ▁육 softmax value:tensor(0.0034, grad_fn=<SelectBackward>)\n",
      "selected token: 체적 softmax value:tensor(0.5611, grad_fn=<SelectBackward>)\n",
      "selected token: ▁고통 softmax value:tensor(0.9192, grad_fn=<SelectBackward>)\n",
      "selected token: 이 softmax value:tensor(0.6109, grad_fn=<SelectBackward>)\n",
      "selected token: ▁일 softmax value:tensor(0.0023, grad_fn=<SelectBackward>)\n",
      "selected token: 순간 softmax value:tensor(0.8648, grad_fn=<SelectBackward>)\n",
      "selected token: ▁머릿 softmax value:tensor(0.0034, grad_fn=<SelectBackward>)\n",
      "selected token: 속을 softmax value:tensor(0.2784, grad_fn=<SelectBackward>)\n",
      "selected token: ▁온통 softmax value:tensor(0.0182, grad_fn=<SelectBackward>)\n",
      "selected token: ▁메 softmax value:tensor(0.0967, grad_fn=<SelectBackward>)\n",
      "selected token: 우고 softmax value:tensor(0.0818, grad_fn=<SelectBackward>)\n",
      "selected token: ▁와 softmax value:tensor(0.0161, grad_fn=<SelectBackward>)\n",
      "selected token: ▁그를 softmax value:tensor(0.7679, grad_fn=<SelectBackward>)\n",
      "selected token: ▁덮 softmax value:tensor(0.1071, grad_fn=<SelectBackward>)\n",
      "selected token: 쳤다 softmax value:tensor(0.6300, grad_fn=<SelectBackward>)\n",
      "서핑 보드를 타는 한 남자만이 조용히 요람에 폴짝폴짝 모여들어 자신의 몸 안에 장기가 가득 차도록 폴짝 뛰고 있었다.\n",
      "바닥에 자기 주전자 네 개까지 내놓은 건장한 청년이 다른 사람 앞에 주름을 잡을 사이에 어디 한 눈 팔 여유가 없어 보였다.\n",
      "그냥 일어나 맥주 잔을 앞에 놓고 지하실로 들어갔다.\n",
      "한낮의 열기를 식히려는 본능이 서도 건실하게 몸에 익은 상태였다.\n",
      "그걸 본 소년은 이 거대한 무쇠 난로에서 생쥐를 발견하곤 생쥐를 놓아주었다.\n",
      "병사가 어슬렁 거리며 그를 향해 총을  발사했지만 정확히 몸 속의 생쥐를 맞추지는 못했다.\n",
      "깜짝 놀란 병사가 살살 나무라며 난로 쪽으로 기어갔어요.\n",
      "그는 여우가 떠올랐던 그 젊은이의 얼굴에 경련이 일며 화를 내며 고개를 쳐들고 서 있질 못했다.\n",
      "마치 그의 악마적인 마음씨가 잔인한 형을 또 한 번 맞은 듯 했기 때문이다.\n",
      "순간적인 화와 그로 인한 자신의 육체적 고통이 일순간 머릿속을 온통 메우고 와 그를 덮쳤다\n",
      "time is  41.79342865943909\n"
     ]
    }
   ],
   "source": [
    "#tok_path = get_tokenizer()\n",
    "#model, vocab = get_pytorch_kogpt2_model()\n",
    "tok = SentencepieceTokenizer(tok_path,  num_best=0, alpha=0)\n",
    "\n",
    "sent = input('문장 입력: ')\n",
    "\n",
    "toked = tok(sent)\n",
    "print(toked)\n",
    "count = 0\n",
    "output_size = 200 # 출력하고자 하는 토큰 갯수\n",
    "start = time.time()\n",
    "'''\n",
    "cycle = 100\n",
    "while cycle :\n",
    "  input_ids = torch.tensor([vocab[vocab.bos_token],]  + vocab[toked]).unsqueeze(0)\n",
    "  pred = model(input_ids)[0]\n",
    "  gen = vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist())[-1]\n",
    "  print(gen)\n",
    "  if gen == '</s>':\n",
    "      break\n",
    "  sent += gen.replace('▁', ' ')\n",
    "  toked = tok(sent)\n",
    "  cycle -= 1\n",
    "\n",
    "print(sent)\n",
    "'''\n",
    "while 1:\n",
    "  input_ids = torch.tensor([vocab[vocab.bos_token],]  + vocab[toked]).unsqueeze(0)\n",
    "  predicts = model(input_ids)\n",
    "  pred = predicts[0]\n",
    "    \n",
    "  last_pred = pred.squeeze()[-1]\n",
    "  # top_p 샘플링 방법\n",
    "  # sampling.py를 통해 random, top-k, top-p 선택 가능.\n",
    "  gen = sampling.top_p(last_pred, vocab, 0.85)\n",
    "  #gen = sampling.top_k(last_pred, vocab, 5)\n",
    "\n",
    "  if count>output_size:\n",
    "    sent += gen.replace('▁', ' ')\n",
    "    toked = tok(sent)\n",
    "    count =0\n",
    "    break\n",
    "  sent += gen.replace('▁', ' ')\n",
    "  toked = tok(sent)\n",
    "  count += 1\n",
    "\n",
    "\n",
    "for s in kss.split_sentences(sent):\n",
    "    print(s)\n",
    "    \n",
    "print(\"time is \", time.time() -  start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "by1zYlUWudTX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtfJN38fyVMYrNDJ2yGEW7",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NovelGenerator.ipynb",
   "provenance": [
    {
     "file_id": "1ChkS56shytnc2x8rXwaYwhhMJYPEQxaT",
     "timestamp": 1584444701945
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
