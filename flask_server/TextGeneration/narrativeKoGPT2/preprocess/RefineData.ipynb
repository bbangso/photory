{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data import sentencePieceTokenizer, toString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "sentencepieceTokenizer= sentencePieceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Dataset/Grimm_Samples_minimal.txt', 'r', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "untokenized_file = open('Dataset/untokenized_Grimm_Samples_minimal.txt', 'w', encoding='utf-8')\n",
    "tokenized_file = open('Dataset/tokenized_Grimm_Samples_minimal.txt', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "untokenized = \"\"\n",
    "tokenized = \"\"\n",
    "data_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿하지만 그는 나이가 많아 보였고 무엇보다 새하얗고 기다란 턱수염을 하고 있는 자였다.  “고 녀석 참,”라며 노인(유령)이 큰소리로 말했다. “넌 이제 등골이 오싹해질 게다, 왜냐면 넌 곧 죽게 될 테니까.” “놀고 있네,”라며 청년(주인공)이 말했다. “그런 소리는 내가 죽고 나서나 해야 하는 거 아냐.” “네 놈을 뭉개주지.”라며 그 친구(노인 유령)가 말했다. “어이, 어이, 그렇게 큰 소리 치지 말라고. 힘은 내가 당신보다 더 있을 테니 말이야.” “어디 한 번 겨뤄볼까,”라며 그 노인(유령)이 말했다. “만약 네가 나보다 쌔면, 놓아주지… 어디, 겨뤄보자고.” 그런 다음 노인(유령)은 청년(주인공)을 데리고 껌껌한 통로들을 지나 대장간으로 데리고 갔다.  노인(유령)이 도끼 한 자루를 집어 들더니 ‘모루’를 한 방에 내려쳐 땅에다 받아버렸다.  “놀고 있네, 난 그보다 더 잘할 자신 있다고.”라며 청년이 말하더니 다른 ‘모루’(받침으로 사용하는 쇳덩이)로 갔다.  노인은 청년 옆에서 직접 보고 싶었다.  그러다 노인의 긴 턱수염이 모루 위에 놓이고 말았다.  그때 청년이 도끼를 집어 들더니 한 방에 모루를 쪼갰는데, 그 바람에 노인의 턱수염이 쪼개진(찢어진) 모루에 끼고 말았다.  “내가 도리어 당신을 잡았군,”라며 청년이 말했다. “자 누가 죽나 보자고.” 그런 다음 청년은 철봉(철로 된 막대기)을 부여잡더니 그걸로 노인(유령)을 노인이 신음 소리를 내며 “막대한 재물(=돈)을 줄 테니” 제발 그만하라고 애걸복걸 할 때까지 때렸다.  그러자 청년은 철봉을 던져버리고 노인(유령)을 놓아주었다.  노인(유령)은 청년을 데리고 다시 ‘성’으로 돌아와 성 지하실에 있던 세 상자의 궤짝들을 보여주었다. 거기엔 금은보화가 가득했다.  “이 중,”라며 노인(유령)이 말했다. “이 중 하나는 가난한 사람들에게 나누어줄 것이며, 다른 하나는 왕깨 드릴 것이며, 세 번째 궤짝에 든 게 자네의 것이네.” 그러는 사이에 밤 12시를 알리는 종이 울리자, 유령(노인)이 흔적도 없이 사라져다.  그리하여 청년은 다시 혼자 어둠 속에 남게 되었다.  “다행히 출구를 찾을 순 있겠어,”라며 청년이 말했다. 어둠이 눈에 익자 곧 방으로 가는 출구를 찾아 청년은 다시 불 옆에 와서 잠이 들었다.  다음날 아침 왕이 와 말했다.  “그래 이젠 좀 등골이 오걸 배웠는감?” “아뇨,”라고 청년(주인공)이 말했다. “그게 도대체 뭔데요? 제 죽은 사촌동생도 여기 왔다 갔고, 턱수염을 기른 노인네도 다녀갔지만 지하창고에 가득 든 금은보화만 보여주고 만 걸요. 아주도 제게 등골이 오싹한 게 뭔지 알려주지 않았어요.” “자자,”라면 왕이 말했다. “성으로 가서 내 딸과 결혼식을 올리게.” “성은이 망극하나이다.”라며 청년이 말했다. “하지만 등골이 오싹한 걸 어째 좀 배웠음 하는 마음만은 여전해요.” 그런 다음 노인(유령)이 준 금은보화가 운반되었고, 그리고 결혼식도 성대하게 잘 열렸다.  하지만 젊은 왕(주인공)이 자신의 왕비를 무척 사랑했고 결혼생활도 행복 그 자체였지만, 젊은 왕은 여전히 시간만 나면 중얼거렸다.  “등골이 오싹한 걸 배워야 하는데… 등골이 오싹한 걸 배워야 하는데.” 그래서 마침내 왕비도 짜증만땅이 되고 말았다.  그녀의 시녀(몸종) 하나가 말했다.  “제게 좋은 방법이 있어요. 등골이 오싹한 게 뭔지 왕께서도 곧 배우시게 되실 거예요.” 시녀(몸종. 왕비의 시녀)는 정원에 졸졸 흐르고 있는 개울가로 가 ‘모샘치’를 양동이에 한 가득 담아와 왕비께 건넸다.  그날 밤 젊은 왕(주인공)이 잠을 자고 있는데, 왕비(아내)가 왕의 옷을 벗기곤 시녀에게 건네받았던 ‘양동이에 한 가득 든 모샘치(작은 물고기)와 물’을 왕에게 쏟아 부었다.  그 바람에 작은 물고기들이 왕의 몸 위 여기저기에서 버둥버둥 거렸다.\n",
      "1859\n",
      "tokenized_line :  1857\n",
      "untokenized_line :  1873\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    line = file.readline()\n",
    "\n",
    "    if not line:\n",
    "      untokenized_file.write(untokenized)\n",
    "      tokenized_file.write(tokenized)\n",
    "      break\n",
    "\n",
    "    tokenized_line = sentencepieceTokenizer(line)\n",
    "    print(line)\n",
    "    \n",
    "    # Data length for writing has to under 1022\n",
    "    # input data can get 1024 token\n",
    "    # but we need to use BOS and EOS token\n",
    "    if data_length+len(tokenized_line)+2 >= 1022: # bos와 eos 토큰 갯수 고려 +2\n",
    "      print(data_length+len(tokenized_line)+2)\n",
    "      print('tokenized_line : ', len(tokenized_line))\n",
    "      print('untokenized_line : ', len(line))\n",
    "      untokenized_file.write(untokenized+'\\n')\n",
    "      tokenized_file.write(tokenized+'\\n')\n",
    "\n",
    "      untokenized = \"\"\n",
    "      tokenized = \"\"\n",
    "      data_length = 0\n",
    "\n",
    "    untokenized = untokenized + \"<s>\"+line[:-1] +\"</s>\"\n",
    "    tokenized = tokenized + \"<s>\" + toString(tokenized_line) + \"</s>\"\n",
    "\n",
    "    data_length = data_length+len(tokenized_line) + 2 # bos와 eos 토큰 갯수 고려 +2\n",
    "\n",
    "file.close()\n",
    "untokenized_file.close()\n",
    "tokenized_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
